{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2888fe66-a41f-4faf-a84b-fd0401818bac",
   "metadata": {},
   "source": [
    "Data Science Project: Phage Lysin Sequence Alignment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef5199-9ad9-4822-a751-a7a704dc5d1b",
   "metadata": {},
   "source": [
    "With the ongoing rise of antibiotic resistance in bacteria, including challenging pathogens like Mycobacteria, finding alternative treatments for patients is becoming increasingly urgent. An emerging approach is the use of phage lysins to effectively target and eradicate specific bacterial infections. Lysins are enzymes produced by bacteriophages, they possess domains that adhere to bacterial cell wall components and trigger hydrolysis, ultimately resulting in the elimination of the host bacterium. Understanding the conservation and variability of amino acid sequences, especially in the context of Mycobacteria infections, is crucial for developing effective therapeutic lysin treatments. In this project, we will identify conserved regions, assess sequence similarity, and uncover evolutionary patterns to inform the development of targeted antibacterial therapies, specifically focusing on Mycobacteria skin and lung infections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af999b0a-737a-4143-83b2-d67743ebfe1b",
   "metadata": {},
   "source": [
    "Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782ab4a7-ce25-4c3a-8cb0-7301b038ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import requests\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4762159-d555-4256-a459-b9dbd326437f",
   "metadata": {},
   "source": [
    "Data collection"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93829e59-8824-46e0-a76b-a8c4b5765932",
   "metadata": {},
   "source": [
    "# Fetch genes data from phagesdb API\n",
    "\n",
    "# URL of the API endpoint\n",
    "url = \"https://phagesdb.org/api/genes/\"\n",
    "\n",
    "# Define the chunk size\n",
    "chunk_size = 10000  # You can adjust this value based on your needs\n",
    "\n",
    "# Initialize variables for pagination\n",
    "page = 1\n",
    "total_records = None\n",
    "\n",
    "# Open the JSON file in write mode\n",
    "with open('phagesdb_genes.json', 'w') as file:\n",
    "    # Write an opening bracket to indicate the start of a JSON array\n",
    "    file.write(\"[\\n\")\n",
    "   \n",
    "    # Fetch data in chunks until all records are retrieved\n",
    "    while total_records is None or (page - 1) * chunk_size < total_records:\n",
    "        # Make a request to the API with pagination parameters\n",
    "        response = requests.get(url, params={'page': page, 'page_size': chunk_size})\n",
    "       \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Convert the response to JSON format\n",
    "            data = response.json()\n",
    "           \n",
    "            # Update the total number of records if it's not set yet\n",
    "            if total_records is None:\n",
    "                total_records = data['count']\n",
    "           \n",
    "            # Write the fetched data from the current page to the JSON file\n",
    "            json.dump(data['results'], file)\n",
    "           \n",
    "            # Write a comma after each chunk except for the last one\n",
    "            if (page - 1) * chunk_size + len(data['results']) < total_records:\n",
    "                file.write(\",\\n\")\n",
    "           \n",
    "            # Print a message to indicate progress\n",
    "            print(f\"Fetched {len(data['results'])} records (Chunk {page})\")\n",
    "        else:\n",
    "            # Print an error message if the request was not successful\n",
    "            print(f\"Error fetching data: {response.status_code}\")\n",
    "            break\n",
    "       \n",
    "        # Increment the page number for the next request\n",
    "        page += 1\n",
    "   \n",
    "    # Write a closing bracket to indicate the end of the JSON array\n",
    "    file.write(\"\\n]\\n\")\n",
    "\n",
    "# Print a message to indicate successful completion\n",
    "print(\"Data fetched and saved successfully!\")\r\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d56342e-e680-4e56-a40c-2ce85395e078",
   "metadata": {},
   "source": [
    "#Combine outer lists generated from chunk\n",
    "\n",
    "# Read the JSON file\n",
    "with open('phagesdb_genes.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Combine the outer lists\n",
    "combined_data = sum(data, [])\n",
    "\n",
    "# Determine the number of lists in the final JSON data\n",
    "num_lists = len(combined_data)\n",
    "print(\"Number of lists in the final JSON data:\", num_lists)\n",
    "\n",
    "# Define the file path for the new JSON file\n",
    "output_file = 'combined_data_output.json'\n",
    "\n",
    "# Write the combined JSON data to the new file\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(combined_data, file)\n",
    "\n",
    "print(\"Combined JSON data saved to\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4daf15-9224-4b81-bf3e-ab8299e8f3d6",
   "metadata": {},
   "source": [
    "Data Definition and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97ac417c-7d31-42ad-9c66-8b3dc2fa357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering dictionaries...\n",
      "Filtering complete.\n",
      "Saving filtered dictionaries...\n",
      "Filtered dictionaries saved to 'lysin_dictionaries.json'\n",
      "Number of dictionaries saved: 7191\n"
     ]
    }
   ],
   "source": [
    "# Load the combined_data_output.json file\n",
    "input_file_path = 'combined_data_output.json'\n",
    "\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    data = json.load(input_file)\n",
    "\n",
    "# Function to check if any form of \"lysin\" is present in the Notes\n",
    "def contains_lysin(notes):\n",
    "    lysin_pattern = re.compile(r'lysin', re.IGNORECASE)\n",
    "    return bool(lysin_pattern.search(notes))\n",
    "\n",
    "# Filter for dictionaries where the Notes key contains any form of \"lysin\"\n",
    "lysin_dictionaries = []\n",
    "\n",
    "print(\"Filtering dictionaries...\")\n",
    "\n",
    "for item in data:\n",
    "    notes = item.get('Notes', '')\n",
    "    if contains_lysin(notes):\n",
    "        lysin_dictionaries.append(item)\n",
    "\n",
    "print(\"Filtering complete.\")\n",
    "\n",
    "# Specify the path to the new JSON file\n",
    "output_file_path = 'lysin_dictionaries.json'\n",
    "\n",
    "# Write the filtered dictionaries to the new JSON file\n",
    "print(\"Saving filtered dictionaries...\")\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    json.dump(lysin_dictionaries, output_file)\n",
    "\n",
    "num_saved_dictionaries = len(lysin_dictionaries)\n",
    "print(f\"Filtered dictionaries saved to '{output_file_path}'\")\n",
    "print(f\"Number of dictionaries saved: {num_saved_dictionaries}\")\n",
    "\n",
    "# Load the combined_data_output.json file\n",
    "input_file_path = 'combined_data_output.json'\n",
    "\n",
    "with open(input_file_path, 'r') as input_file:\n",
    "    combined_data_output = json.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557a14b4-f3d9-46f1-a4d9-e59e466a23df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnested data saved to: lysin_unnested_data.json\n"
     ]
    }
   ],
   "source": [
    "# Un-nest PhageID dictionary in json file \n",
    "\n",
    "# Load the JSON data\n",
    "with open('lysin_dictionaries.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Iterate through each gene entry\n",
    "for gene_entry in data:\n",
    "    # Unpack the PhageID dictionary\n",
    "    phage_id_dict = gene_entry.pop('PhageID')\n",
    "    for key, value in phage_id_dict.items():\n",
    "        # Add each key-value pair to the outer dictionary\n",
    "        gene_entry[key] = value\n",
    "\n",
    "# Save the modified data to a new JSON file\n",
    "output_file_path = 'lysin_unnested_data.json'\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    json.dump(data, output_file, indent=4)\n",
    "\n",
    "print(\"Unnested data saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3f54c8-47f7-448d-a8e0-e39ca2bb3b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dictionaries: 7191\n",
      "Number of lists: 7192\n",
      "Total number of elements: 93483\n"
     ]
    }
   ],
   "source": [
    "# Investigate contents of json file\n",
    "\n",
    "# Open the JSON file and load the data\n",
    "with open('lysin_unnested_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize counters for dictionaries, lists, and total elements\n",
    "num_dicts = 0\n",
    "num_lists = 0\n",
    "num_elements = 0\n",
    "\n",
    "# Function to recursively count elements\n",
    "def count_elements(data):\n",
    "    global num_dicts, num_lists, num_elements\n",
    "    if isinstance(data, dict):\n",
    "        num_dicts += 1\n",
    "        # Check if the key 'key' exists in the dictionary\n",
    "        if 'key' in data:\n",
    "            print(\"Type of 'key':\", type(data['key']))\n",
    "        for value in data.values():\n",
    "            count_elements(value)\n",
    "    elif isinstance(data, list):\n",
    "        num_lists += 1\n",
    "        for item in data:\n",
    "            count_elements(item)\n",
    "    else:\n",
    "        num_elements += 1\n",
    "\n",
    "# Call the function to count elements\n",
    "count_elements(data)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of dictionaries:\", num_dicts)\n",
    "print(\"Number of lists:\", num_lists)\n",
    "print(\"Total number of elements:\", num_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b27b59-90b3-42fb-89b2-2f88309fad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: GeneID | Type: <class 'str'>\n",
      "Key: phams | Type: <class 'list'>\n",
      "Key: Start | Type: <class 'int'>\n",
      "Key: Stop | Type: <class 'int'>\n",
      "Key: Length | Type: <class 'int'>\n",
      "Key: Name | Type: <class 'str'>\n",
      "Key: translation | Type: <class 'str'>\n",
      "Key: Orientation | Type: <class 'str'>\n",
      "Key: Notes | Type: <class 'str'>\n",
      "Key: PhageID | Type: <class 'str'>\n",
      "Key: Accession | Type: <class 'str'>\n",
      "Key: HostStrain | Type: <class 'str'>\n",
      "Key: Cluster | Type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Print object types of keys in the first entry\n",
    "\n",
    "# Get the first entry\n",
    "first_entry = data[0]\n",
    "\n",
    "for key, value in first_entry.items():\n",
    "    print(\"Key:\", key, \"| Type:\", type(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311bfc5f-c2e4-4f30-84a3-c9e3eeecdefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: GeneID | Total Value Count: 7191\n",
      "Key: phams | Total Value Count: 7191\n",
      "Key: Start | Total Value Count: 7191\n",
      "Key: Stop | Total Value Count: 7191\n",
      "Key: Length | Total Value Count: 7191\n",
      "Key: Name | Total Value Count: 7191\n",
      "Key: translation | Total Value Count: 7191\n",
      "Key: Orientation | Total Value Count: 7191\n",
      "Key: Notes | Total Value Count: 7191\n",
      "Key: PhageID | Total Value Count: 7191\n",
      "Key: Accession | Total Value Count: 7181\n",
      "Key: HostStrain | Total Value Count: 7191\n",
      "Key: Cluster | Total Value Count: 7126\n"
     ]
    }
   ],
   "source": [
    "# Print number of values for each key \n",
    "\n",
    "# Dictionary to store total counts for each key\n",
    "total_counts = {}\n",
    "\n",
    "# Iterate through each key\n",
    "for key in data[0].keys():\n",
    "    # Initialize count for the key\n",
    "    count = 0\n",
    "    # Iterate through each entry in the data\n",
    "    for entry in data:\n",
    "        # Check if the value for the key is not missing\n",
    "        if entry[key] != '' and entry[key] is not None:\n",
    "            count += 1\n",
    "    # Store the count for the key\n",
    "    total_counts[key] = count\n",
    "\n",
    "# Print the total counts for each key\n",
    "for key, count in total_counts.items():\n",
    "    print(f\"Key: {key} | Total Value Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1941f334-c25d-4627-8e2e-cfdf444f00b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: GeneID | Missing Value Count: 0\n",
      "Key: phams | Missing Value Count: 0\n",
      "Key: Start | Missing Value Count: 0\n",
      "Key: Stop | Missing Value Count: 0\n",
      "Key: Length | Missing Value Count: 0\n",
      "Key: Name | Missing Value Count: 0\n",
      "Key: translation | Missing Value Count: 0\n",
      "Key: Orientation | Missing Value Count: 0\n",
      "Key: Notes | Missing Value Count: 0\n",
      "Key: PhageID | Missing Value Count: 0\n",
      "Key: Accession | Missing Value Count: 10\n",
      "Key: HostStrain | Missing Value Count: 0\n",
      "Key: Cluster | Missing Value Count: 65\n"
     ]
    }
   ],
   "source": [
    "# Print missing values for each key\n",
    "\n",
    "# Dictionary to store missing value counts\n",
    "missing_counts = {}\n",
    "\n",
    "# Iterate through each key\n",
    "for key in data[0].keys():\n",
    "    # Initialize count for the key\n",
    "    count = 0\n",
    "    # Iterate through each entry in the data\n",
    "    for entry in data:\n",
    "        # Check if the value for the key is missing\n",
    "        if entry[key] == '' or entry[key] is None:\n",
    "            count += 1\n",
    "    # Store the count for the key\n",
    "    missing_counts[key] = count\n",
    "\n",
    "# Print the missing value counts\n",
    "for key, count in missing_counts.items():\n",
    "    print(f\"Key: {key} | Missing Value Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865b383-0257-49f6-a59d-749739554236",
   "metadata": {},
   "source": [
    "Cluster info is sometimes unknown and missing from this dataset. It will not affect the downsteam analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2461379c-35ec-4d2e-a36a-98b2c0acb68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: GeneID | Duplicate Value Count: 0\n",
      "Key: phams | Duplicate Value Count: 7007\n",
      "Key: Start | Duplicate Value Count: 2227\n",
      "Key: Stop | Duplicate Value Count: 2284\n",
      "Key: Length | Duplicate Value Count: 6778\n",
      "Key: Name | Duplicate Value Count: 2962\n",
      "Key: translation | Duplicate Value Count: 3464\n",
      "Key: Orientation | Duplicate Value Count: 7189\n",
      "Key: Notes | Duplicate Value Count: 7128\n",
      "Key: PhageID | Duplicate Value Count: 2962\n",
      "Key: Accession | Duplicate Value Count: 2968\n",
      "Key: HostStrain | Duplicate Value Count: 7179\n",
      "Key: Cluster | Duplicate Value Count: 6889\n"
     ]
    }
   ],
   "source": [
    "# Count Duplicate values for each key\n",
    "\n",
    "# Dictionary to store duplicate value counts\n",
    "duplicate_counts = {}\n",
    "\n",
    "# Iterate through each key\n",
    "for key in data[0].keys():\n",
    "    # Initialize a set to store unique values for the key\n",
    "    unique_values = set()\n",
    "    # Initialize count for duplicates for the key\n",
    "    count = 0\n",
    "    # Iterate through each entry in the data\n",
    "    for entry in data:\n",
    "        # Check if the value for the key is a list\n",
    "        if isinstance(entry[key], list):\n",
    "            # Iterate through each element in the list\n",
    "            for item in entry[key]:\n",
    "                # Check if the item is a duplicate\n",
    "                if item in unique_values:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    unique_values.add(item)\n",
    "        else:\n",
    "            # Check if the value for the key is a duplicate\n",
    "            if entry[key] in unique_values:\n",
    "                count += 1\n",
    "            else:\n",
    "                unique_values.add(entry[key])\n",
    "    # Store the count for duplicates for the key\n",
    "    duplicate_counts[key] = count\n",
    "\n",
    "# Print the duplicate value counts\n",
    "for key, count in duplicate_counts.items():\n",
    "    print(f\"Key: {key} | Duplicate Value Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3652a0e1-2fef-49f7-8282-ce87cd91c73b",
   "metadata": {},
   "source": [
    "Most importantly each dictionary entry has a unique GeneID, it is not suprising that other Keys contain duplicate values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18ea89c-c9b5-4aa7-8a99-da652ab734a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes: b'lysin B' | Count: 2519\n",
      "Notes: b'lysin A' | Count: 2772\n",
      "Notes: b'endolysin' | Count: 1010\n",
      "Notes: b'putative lysin A' | Count: 8\n",
      "Notes: b'putative lysin B' | Count: 6\n",
      "Notes: b'LysM-like endolysin' | Count: 28\n",
      "Notes: b'lysin A, protease M23 domain' | Count: 63\n",
      "Notes: b'lysin' | Count: 28\n",
      "Notes: b'lysin A, N-acetylmuramoyl-L-alanine amidase domain' | Count: 100\n",
      "Notes: b'lysin A, L-Ala-D-Glu peptidase domain' | Count: 156\n",
      "Notes: b'lysin A, glycosyl hydrolase domain' | Count: 213\n",
      "Notes: b'lysin A, protease C39 domain' | Count: 93\n",
      "Notes: b'lysin A, N-acetylmuramoyl-L-alanine amidase' | Count: 1\n",
      "Notes: b'lysin A, M23 peptidase domain' | Count: 2\n",
      "Notes: b'lysin A, amidase domain' | Count: 3\n",
      "Notes: b'endolysin, L-Ala-D-Glu peptidase domain' | Count: 41\n",
      "Notes: b'endolysin, N-acetylmuramoyl-L-alanine amidase domain' | Count: 46\n",
      "Notes: b'endolysin, protease M23 domain' | Count: 6\n",
      "Notes: b'lysin A, N-acetylmuramoyl-L-alanine' | Count: 2\n",
      "Notes: b'gp24, lysin' | Count: 1\n",
      "Notes: b'lysin A, L-ala D-glu peptidase domain' | Count: 1\n",
      "Notes: b'lysin A glycosidase domain' | Count: 1\n",
      "Notes: b'lysin A amidase domain' | Count: 1\n",
      "Notes: b'lysin A peptidase domain' | Count: 1\n",
      "Notes: b'lysin A, N-acetylmuramoyl-L-alanine amides domain' | Count: 3\n",
      "Notes: b'lysin A, l-ala d-glu peptidase domain' | Count: 1\n",
      "Notes: b'lysin A, protease M15 domain' | Count: 11\n",
      "Notes: b'lysin A N-acetylmuramoyl-L-alanine amidase domain' | Count: 1\n",
      "Notes: b'lysin A L-Ala-D-Glu peptidase domain' | Count: 2\n",
      "Notes: b'endolysin, protease C39 domain' | Count: 3\n",
      "Notes: b'endolysin, glycosyl hydrolase domain' | Count: 4\n",
      "Notes: b'lysin A, protease domain' | Count: 3\n",
      "Notes: b'endolysin protease M15 domain' | Count: 1\n",
      "Notes: b'endolysin protease M23 domain' | Count: 1\n",
      "Notes: b'lysin A protease C39 domain' | Count: 1\n",
      "Notes: b'lysin A, peptidoglycan recogniton protein' | Count: 1\n",
      "Notes: b'lysin A, N-acetyl-B-D-muramidase domain' | Count: 1\n",
      "Notes: b'endolysin domain protein' | Count: 2\n",
      "Notes: b'putative lysin' | Count: 20\n",
      "Notes: b'lysin A glycosyl hydrolase domain' | Count: 1\n",
      "Notes: b'lysinB protein' | Count: 1\n",
      "Notes: b'lysin A, GH19 glycoside hydrolase domain' | Count: 1\n",
      "Notes: b'endolysin, protease M15 domain' | Count: 2\n",
      "Notes: b'lysin A, N-acetyl-beta-D-muramidase domain' | Count: 1\n",
      "Notes: b'lysin A, peptidase domain' | Count: 5\n",
      "Notes: b'endolysin, peptidase domain' | Count: 2\n",
      "Notes: b'lysinA, hydrolase domain' | Count: 1\n",
      "Notes: b'Lysin A' | Count: 1\n",
      "Notes: b'Lysin B' | Count: 2\n",
      "Notes: b'lysin A, N-acetylmuramoyl-Lalanine amidase domain' | Count: 1\n",
      "Notes: b'lysin A, l-ala-d-glu peptidase domain' | Count: 1\n",
      "Notes: b'endolysin amidase' | Count: 1\n",
      "Notes: b'endolysin endopeptidase/amidase' | Count: 1\n",
      "Notes: b'lysin A, C39 peptidase domain' | Count: 1\n",
      "Notes: b'putative endolysin' | Count: 2\n",
      "Notes: b'endolysin, protease M23 domain and cell wall binding domain' | Count: 1\n",
      "Notes: b'endolysin, protease domain' | Count: 1\n",
      "Notes: b'lysin A, glycosyl hyrdrolase domain' | Count: 1\n",
      "Notes: b'lysin A, L-Ala,-D-Glu peptidase domain' | Count: 1\n",
      "Notes: b'lysin A, M15 protease' | Count: 1\n",
      "Notes: b'lysin A, protease C39' | Count: 1\n",
      "Notes: b'putitive lysin A' | Count: 2\n",
      "Notes: b'putitive lysin B' | Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Investigate notes field and count unique values\n",
    "\n",
    "# Dictionary to store counts of different notes\n",
    "notes_counts = {}\n",
    "\n",
    "# Iterate through each entry in the data\n",
    "for entry in data:\n",
    "    # Extract the value of the \"Notes\" key\n",
    "    notes = entry['Notes']\n",
    "    # Check if the value is not empty\n",
    "    if notes:\n",
    "        # Update the count for the note value\n",
    "        if notes in notes_counts:\n",
    "            notes_counts[notes] += 1\n",
    "        else:\n",
    "            notes_counts[notes] = 1\n",
    "\n",
    "# Print all unique note values and their counts\n",
    "for note, count in notes_counts.items():\n",
    "    print(f\"Notes: {note} | Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f63ace-20e1-427c-9d0a-1127b4d32502",
   "metadata": {},
   "source": [
    "The Notes field contains many different iterations of lysin. In order to proceed with analysis we will determine how many entries contain the following: lysin A, lysin B, endolysin, and other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87fc4ec5-4d55-42ab-bc7f-68e87e878d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries containing any iteration of lysin A, lysin B, or endolysin: 7192\n",
      "Lysin A count: 3460\n",
      "Lysin B count: 2529\n",
      "Endolysin count: 1152\n",
      "Other lysin count: 51\n",
      "\n",
      "Notes entries that are not lysin A, lysin B, or endolysin:\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters for lysin A, lysin B, and endolysin\n",
    "lysin_a_count = 0\n",
    "lysin_b_count = 0\n",
    "endolysin_count = 0\n",
    "other_lysin_count = 0  # Count for notes containing 'lysin' but not categorized as lysin A, lysin B, or endolysin\n",
    "\n",
    "# List to store notes entries that are not lysin A, lysin B, or endolysin\n",
    "other_notes = []\n",
    "\n",
    "# Iterate through each entry in the data\n",
    "for entry in data:\n",
    "    # Extract the value of the \"Notes\" key\n",
    "    notes = entry['Notes']\n",
    "    # Check if the value is not empty\n",
    "    if notes:\n",
    "        # Convert notes to lowercase for case-insensitive comparison\n",
    "        notes_lower = notes.lower()\n",
    "        # Check if the entry contains any iteration of lysin A, lysin B, or endolysin (case-insensitive)\n",
    "        if any(keyword in notes_lower for keyword in ['lysin a', 'lysin b', 'endolysin', 'lysinA', 'lysinB']):\n",
    "            # Increment respective counters\n",
    "            if 'lysin a' in notes_lower or 'lysinA' in notes_lower:\n",
    "                lysin_a_count += 1\n",
    "            if 'lysin b' in notes_lower or 'lysinB' in notes_lower:\n",
    "                lysin_b_count += 1\n",
    "            if 'endolysin' in notes_lower:\n",
    "                endolysin_count += 1\n",
    "        # Check if the entry contains 'lysin' but is not categorized as lysin A, lysin B, or endolysin\n",
    "        elif 'lysin' in notes_lower:\n",
    "            other_lysin_count += 1\n",
    "        else:\n",
    "            # If the note is not lysin A, lysin B, or endolysin, add it to other_notes list\n",
    "            other_notes.append(notes)\n",
    "\n",
    "# Calculate total count\n",
    "total_lysin_notes = lysin_a_count + lysin_b_count + endolysin_count + other_lysin_count\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Total number of entries containing any iteration of lysin A, lysin B, or endolysin: {total_lysin_notes}\")\n",
    "print(f\"Lysin A count: {lysin_a_count}\")\n",
    "print(f\"Lysin B count: {lysin_b_count}\")\n",
    "print(f\"Endolysin count: {endolysin_count}\")\n",
    "print(f\"Other lysin count: {other_lysin_count}\")\n",
    "\n",
    "# Print all notes entries that are not lysin A, lysin B, or endolysin\n",
    "print(\"\\nNotes entries that are not lysin A, lysin B, or endolysin:\")\n",
    "for note in other_notes:\n",
    "    print(note)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd1854e8-e2f4-417a-acb3-97bac48c0e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New JSON file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Re-classify notes entries to lysin A, lysin B, endolysin, and putative lysin  \n",
    "\n",
    "# Replace note values with the desired ones\n",
    "for entry in data:\n",
    "    notes = entry['Notes']\n",
    "    if notes:\n",
    "        notes_lower = notes.lower()\n",
    "        if 'lysin a' in notes_lower or 'lysinA' in notes_lower:\n",
    "            entry['Notes'] = 'lysin A'\n",
    "        elif 'lysin b' in notes_lower or 'lysinB' in notes_lower:\n",
    "            entry['Notes'] = 'lysin B'\n",
    "        elif 'endolysin' in notes_lower:\n",
    "            entry['Notes'] = 'endolysin'\n",
    "        elif 'lysin' in notes_lower:\n",
    "            entry['Notes'] = 'putative lysin'\n",
    "\n",
    "# Specify the path to save the new JSON file\n",
    "new_json_file_path = \"modified_data.json\"\n",
    "\n",
    "# Save the modified data as JSON\n",
    "with open(new_json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)\n",
    "\n",
    "print(\"New JSON file saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15966a89-d2f8-478f-a5cb-595d8f442457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: lysin B | Count: 2529\n",
      "Note: lysin A | Count: 3460\n",
      "Note: endolysin | Count: 1151\n",
      "Note: putative lysin | Count: 51\n",
      "Total count after modifications: 7192\n"
     ]
    }
   ],
   "source": [
    "# Investigate notes field and count unique values\n",
    "\n",
    "# Dictionary to store counts of different notes\n",
    "notes_counts = {}\n",
    "\n",
    "# Iterate through each entry in the data\n",
    "for entry in data:\n",
    "    # Extract the value of the \"Notes\" key\n",
    "    notes = entry['Notes']\n",
    "    # Check if the value is not empty\n",
    "    if notes:\n",
    "        # Update the count for the note value\n",
    "        if notes in notes_counts:\n",
    "            notes_counts[notes] += 1\n",
    "        else:\n",
    "            notes_counts[notes] = 1\n",
    "\n",
    "# Print all unique note values and their counts\n",
    "for note, count in notes_counts.items():\n",
    "    print(f\"Note: {note} | Count: {count}\")\n",
    "\n",
    "# Calculate total count\n",
    "total_count = lysin_a_count + lysin_b_count + endolysin_count + other_lysin_count\n",
    "\n",
    "# Print the total count\n",
    "print(f\"Total count after modifications: {total_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606fb6c-178f-4e6d-ad7f-29c063062937",
   "metadata": {},
   "source": [
    "json file has been cleaned and data is ready for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab42f68-d745-4828-b3ff-9d494fe4e105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
